{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "from operator import itemgetter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = '''Widely used in knowledge-driven organizations, text mining is the process of examining large collections of documents to discover new information or help answer specific research questions.\n",
    "\n",
    "Text mining identifies facts, relationships and assertions that would otherwise remain buried in the mass of textual big data. Once extracted, this information is converted into a structured form that can be further analyzed, or presented directly using clustered HTML tables, mind maps, charts, etc. Text mining employs a variety of methodologies to process the text, one of the most important of these being Natural Language Processing (NLP).\n",
    "\n",
    "The structured data created by text mining can be integrated into databases, data warehouses or business intelligence dashboards and used for descriptive, prescriptive or predictive analytics.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "total_words = doc.split()\n",
    "total_word_length = len(total_words)\n",
    "print(total_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "total_sentences = tokenize.sent_tokenize(doc)\n",
    "total_sent_len = len(total_sentences)\n",
    "print(total_sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Widely': 0.008333333333333333, 'used': 0.016666666666666666, 'knowledge-driven': 0.008333333333333333, 'organizations,': 0.008333333333333333, 'text': 0.016666666666666666, 'mining': 0.03333333333333333, 'process': 0.016666666666666666, 'examining': 0.008333333333333333, 'large': 0.008333333333333333, 'collections': 0.008333333333333333, 'documents': 0.008333333333333333, 'discover': 0.008333333333333333, 'new': 0.008333333333333333, 'information': 0.016666666666666666, 'help': 0.008333333333333333, 'answer': 0.008333333333333333, 'specific': 0.008333333333333333, 'research': 0.008333333333333333, 'questions': 0.008333333333333333, 'Text': 0.016666666666666666, 'identifies': 0.008333333333333333, 'facts,': 0.008333333333333333, 'relationships': 0.008333333333333333, 'assertions': 0.008333333333333333, 'would': 0.008333333333333333, 'otherwise': 0.008333333333333333, 'remain': 0.008333333333333333, 'buried': 0.008333333333333333, 'mass': 0.008333333333333333, 'textual': 0.008333333333333333, 'big': 0.008333333333333333, 'data': 0.025, 'Once': 0.008333333333333333, 'extracted,': 0.008333333333333333, 'converted': 0.008333333333333333, 'structured': 0.016666666666666666, 'form': 0.008333333333333333, 'analyzed,': 0.008333333333333333, 'presented': 0.008333333333333333, 'directly': 0.008333333333333333, 'using': 0.008333333333333333, 'clustered': 0.008333333333333333, 'HTML': 0.008333333333333333, 'tables,': 0.008333333333333333, 'mind': 0.008333333333333333, 'maps,': 0.008333333333333333, 'charts,': 0.008333333333333333, 'etc': 0.008333333333333333, 'employs': 0.008333333333333333, 'variety': 0.008333333333333333, 'methodologies': 0.008333333333333333, 'text,': 0.008333333333333333, 'one': 0.008333333333333333, 'important': 0.008333333333333333, 'Natural': 0.008333333333333333, 'Language': 0.008333333333333333, 'Processing': 0.008333333333333333, '(NLP)': 0.008333333333333333, 'The': 0.008333333333333333, 'created': 0.008333333333333333, 'integrated': 0.008333333333333333, 'databases,': 0.008333333333333333, 'warehouses': 0.008333333333333333, 'business': 0.008333333333333333, 'intelligence': 0.008333333333333333, 'dashboards': 0.008333333333333333, 'descriptive,': 0.008333333333333333, 'prescriptive': 0.008333333333333333, 'predictive': 0.008333333333333333, 'analytics': 0.008333333333333333}\n"
     ]
    }
   ],
   "source": [
    "tf_score = {}\n",
    "for each_word in total_words:\n",
    "    each_word = each_word.replace('.','')\n",
    "    if each_word not in stop_words:\n",
    "        if each_word in tf_score:\n",
    "            tf_score[each_word] += 1\n",
    "        else:\n",
    "            tf_score[each_word] = 1\n",
    "\n",
    "# Dividing by total_word_length for each dictionary element\n",
    "tf_score.update((x, y/int(total_word_length)) for x, y in tf_score.items())\n",
    "print(tf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sent(word, sentences): \n",
    "    final = [all([w in x for w in word]) for x in sentences] \n",
    "    sent_len = [sentences[i] for i in range(0, len(final)) if final[i]]\n",
    "    return int(len(sent_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Widely': 1.6094379124341003, 'used': 0.0, 'knowledge-driven': 1.6094379124341003, 'organizations,': 1.6094379124341003, 'text': 0.0, 'mining': 0.0, 'process': 0.0, 'examining': 1.6094379124341003, 'large': 1.6094379124341003, 'collections': 1.6094379124341003, 'documents': 1.6094379124341003, 'discover': 1.6094379124341003, 'new': 1.6094379124341003, 'information': 0.0, 'help': 1.6094379124341003, 'answer': 1.6094379124341003, 'specific': 1.6094379124341003, 'research': 1.6094379124341003, 'questions': 1.6094379124341003, 'Text': 0.22314355131420976, 'identifies': 1.6094379124341003, 'facts,': 1.6094379124341003, 'relationships': 1.6094379124341003, 'assertions': 1.6094379124341003, 'would': 1.6094379124341003, 'otherwise': 1.6094379124341003, 'remain': 1.6094379124341003, 'buried': 1.6094379124341003, 'mass': 1.6094379124341003, 'textual': 1.6094379124341003, 'big': 1.6094379124341003, 'data': 0.0, 'Once': 1.6094379124341003, 'extracted,': 1.6094379124341003, 'converted': 1.6094379124341003, 'structured': 0.0, 'form': 1.6094379124341003, 'analyzed,': 1.6094379124341003, 'presented': 1.6094379124341003, 'directly': 1.6094379124341003, 'using': 1.6094379124341003, 'clustered': 1.6094379124341003, 'HTML': 1.6094379124341003, 'tables,': 1.6094379124341003, 'mind': 1.6094379124341003, 'maps,': 1.6094379124341003, 'charts,': 1.6094379124341003, 'etc': 1.6094379124341003, 'employs': 1.6094379124341003, 'variety': 1.6094379124341003, 'methodologies': 1.6094379124341003, 'text,': 1.6094379124341003, 'one': 1.6094379124341003, 'important': 1.6094379124341003, 'Natural': 1.6094379124341003, 'Language': 1.6094379124341003, 'Processing': 1.6094379124341003, '(NLP)': 1.6094379124341003, 'The': 1.6094379124341003, 'created': 1.6094379124341003, 'integrated': 1.6094379124341003, 'databases,': 1.6094379124341003, 'warehouses': 1.6094379124341003, 'business': 1.6094379124341003, 'intelligence': 1.6094379124341003, 'dashboards': 1.6094379124341003, 'descriptive,': 1.6094379124341003, 'prescriptive': 1.6094379124341003, 'predictive': 1.6094379124341003, 'analytics': 1.6094379124341003}\n"
     ]
    }
   ],
   "source": [
    "idf_score = {}\n",
    "for each_word in total_words:\n",
    "    each_word = each_word.replace('.','')\n",
    "    if each_word not in stop_words:\n",
    "        if each_word in idf_score:\n",
    "            idf_score[each_word] = check_sent(each_word, total_sentences)\n",
    "        else:\n",
    "            idf_score[each_word] = 1\n",
    "\n",
    "# Performing a log and divide\n",
    "idf_score.update((x, math.log(int(total_sent_len)/y)) for x, y in idf_score.items())\n",
    "\n",
    "print(idf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Widely': 0.013411982603617503, 'used': 0.0, 'knowledge-driven': 0.013411982603617503, 'organizations,': 0.013411982603617503, 'text': 0.0, 'mining': 0.0, 'process': 0.0, 'examining': 0.013411982603617503, 'large': 0.013411982603617503, 'collections': 0.013411982603617503, 'documents': 0.013411982603617503, 'discover': 0.013411982603617503, 'new': 0.013411982603617503, 'information': 0.0, 'help': 0.013411982603617503, 'answer': 0.013411982603617503, 'specific': 0.013411982603617503, 'research': 0.013411982603617503, 'questions': 0.013411982603617503, 'Text': 0.0037190591885701628, 'identifies': 0.013411982603617503, 'facts,': 0.013411982603617503, 'relationships': 0.013411982603617503, 'assertions': 0.013411982603617503, 'would': 0.013411982603617503, 'otherwise': 0.013411982603617503, 'remain': 0.013411982603617503, 'buried': 0.013411982603617503, 'mass': 0.013411982603617503, 'textual': 0.013411982603617503, 'big': 0.013411982603617503, 'data': 0.0, 'Once': 0.013411982603617503, 'extracted,': 0.013411982603617503, 'converted': 0.013411982603617503, 'structured': 0.0, 'form': 0.013411982603617503, 'analyzed,': 0.013411982603617503, 'presented': 0.013411982603617503, 'directly': 0.013411982603617503, 'using': 0.013411982603617503, 'clustered': 0.013411982603617503, 'HTML': 0.013411982603617503, 'tables,': 0.013411982603617503, 'mind': 0.013411982603617503, 'maps,': 0.013411982603617503, 'charts,': 0.013411982603617503, 'etc': 0.013411982603617503, 'employs': 0.013411982603617503, 'variety': 0.013411982603617503, 'methodologies': 0.013411982603617503, 'text,': 0.013411982603617503, 'one': 0.013411982603617503, 'important': 0.013411982603617503, 'Natural': 0.013411982603617503, 'Language': 0.013411982603617503, 'Processing': 0.013411982603617503, '(NLP)': 0.013411982603617503, 'The': 0.013411982603617503, 'created': 0.013411982603617503, 'integrated': 0.013411982603617503, 'databases,': 0.013411982603617503, 'warehouses': 0.013411982603617503, 'business': 0.013411982603617503, 'intelligence': 0.013411982603617503, 'dashboards': 0.013411982603617503, 'descriptive,': 0.013411982603617503, 'prescriptive': 0.013411982603617503, 'predictive': 0.013411982603617503, 'analytics': 0.013411982603617503}\n"
     ]
    }
   ],
   "source": [
    "tf_idf_score = {key: tf_score[key] * idf_score.get(key, 0) for key in tf_score.keys()}\n",
    "print(tf_idf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(dict_elem, n):\n",
    "    result = dict(sorted(dict_elem.items(), key = itemgetter(1), reverse = True)[:n]) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Widely': 0.013411982603617503, 'knowledge-driven': 0.013411982603617503, 'organizations,': 0.013411982603617503, 'examining': 0.013411982603617503, 'large': 0.013411982603617503}\n"
     ]
    }
   ],
   "source": [
    "print(get_top_n(tf_idf_score, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
