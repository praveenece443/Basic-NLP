{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxonomy Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "syns = wordnet.synsets(\"insurance\")\n",
    "classes = []\n",
    "for syn in syns:\n",
    "     for l in syn.lemmas():\n",
    "            classes.append(l.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['insurance' 'policy' 'insurance_policy' 'insurance' 'indemnity'\n",
      " 'insurance']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "taxonomy = np.array(classes)\n",
    "print(taxonomy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "syns = wordnet.synsets(\"insurance\")\n",
    "classes = []\n",
    "for syn in syns:\n",
    "    classes.append(syn.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['promise of reimbursement in the case of loss; paid to people or companies so concerned about hazards that they have made prepayments to an insurance company'\n",
      " 'written contract or certificate of insurance'\n",
      " 'protection against future loss']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "taxonomy = np.array(classes)\n",
    "print(taxonomy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "syns = wordnet.synsets(\"holiday\")\n",
    "classes = []\n",
    "for syn in syns:\n",
    "     for l in syn.lemmas():\n",
    "            classes.append(l.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vacation' 'holiday' 'holiday' 'vacation' 'holiday']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "taxonomy = np.array(classes)\n",
    "print(taxonomy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "syns = wordnet.synsets(\"insurance\")\n",
    "classes = []\n",
    "for syn in syns:\n",
    "     for hyper in syn.hypernyms():\n",
    "            name = hyper.name().split('.')[0]\n",
    "            classes.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['security' 'contract' 'protection']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "hypernyms = np.array(classes)\n",
    "print(hypernyms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "syns = wordnet.synsets(\"insurance\")\n",
    "classes = []\n",
    "for syn in syns:\n",
    "     for hyper in syn.hyponyms():\n",
    "            name = hyper.name().split('.')[0]\n",
    "            classes.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['assurance' 'automobile_insurance' 'business_interruption_insurance'\n",
      " 'coinsurance' 'fire_insurance' 'group_insurance' 'hazard_insurance'\n",
      " 'health_insurance' 'liability_insurance' 'life_insurance'\n",
      " 'malpractice_insurance' 'reinsurance' 'self-insurance' 'term_insurance'\n",
      " 'floater']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "hypernyms = np.array(classes)\n",
    "print(hypernyms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: Sometimes Holonyms, Meronyms and Entilements doesnt come for some words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "syns = wordnet.synsets(\"kitchen\")\n",
    "classes = []\n",
    "for syn in syns:\n",
    "    name1 = syn.part_holonyms()[0].name().split(\".\")[0]\n",
    "    classes.append(name1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dwelling']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "holonyms = np.array(classes)\n",
    "print(holonyms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meronym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "syns = wordnet.synsets(\"movie\")\n",
    "classes = []\n",
    "for syn in syns:\n",
    "    name1 = syn.part_meronyms()[0].name().split(\".\")[0]\n",
    "    classes.append(name1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['credit']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "meronyms = np.array(classes)\n",
    "print(meronyms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entailments (Works for verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "syns = wordnet.synsets(\"buy\")\n",
    "classes = []\n",
    "for syn in syns:\n",
    "    name1 = syn.entailments()\n",
    "    if len(name1) == []:\n",
    "        print(\"none\")\n",
    "    else:\n",
    "        for name in name1:\n",
    "            for l in name.lemmas():\n",
    "                classes.append(l.name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['choose' 'take' 'select' 'pick_out' 'pay']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "meronyms = np.array(classes)\n",
    "print(meronyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
